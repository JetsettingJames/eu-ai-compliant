- id: human_oversight_mechanisms
  criterion: "Human Oversight Mechanisms"
  description: "High-risk AI systems should be designed to enable human oversight. This includes measures allowing humans to understand the system's capabilities and limitations, monitor its operation, and intervene or halt the system if necessary."
  keywords:
    - "human review"
    - "manual override"
    - "human-in-the-loop"
    - "user intervention"
    - "human oversight"
    - "human control"
    - "stop button"
    - "emergency stop"
  relevant_risk_tiers:
    - "HIGH"
  triggered_by_code_categories:
    - "biometric_processing"
    - "safety_critical_control"
    - "predictive_analytics_law_enforcement"
    - "emotion_recognition"
    - "critical_decision_making_employment"
    - "critical_decision_making_essential_services"
  file_types_to_search:
    - "*.md"
    - "*.txt"
    - "*.py"
    - "*.js"
    - "*.java"
    - "*.cs"
    - "*.html"
    - "*.rst"
    - "*.ipynb"

- id: data_governance_transparency
  criterion: "Data Governance and Transparency"
  description: "High-risk AI systems require robust data governance practices, including transparency about data sources, processing, and quality. Training, validation, and testing data sets should be relevant, representative, free of errors, and complete."
  keywords:
    - "data source"
    - "data lineage"
    - "data processing"
    - "training data"
    - "validation data"
    - "test data"
    - "data quality"
    - "data bias"
    - "data governance"
    - "data sheet"
    - "dataset card"
  relevant_risk_tiers:
    - "HIGH"
  triggered_by_code_categories:
    - "data_processing"
    - "data_storage"
    - "data_transmission"
  file_types_to_search:
    - "*.md"
    - "*.txt"
    - "*.py"
    - "*.ipynb"
    - "*.json"
    - "*.yaml"
    - "*.csv"

- id: ai_system_disclosure
  criterion: "AI System Interaction Disclosure"
  description: "Users interacting with an AI system should be informed that they are interacting with AI, unless this is obvious from the circumstances. This applies to systems like chatbots or those generating content."
  keywords:
    - "chatbot"
    - "virtual assistant"
    - "AI generated"
    - "automated decision"
    - "powered by AI"
    - "this is an AI"
    - "you are talking to an AI"
  relevant_risk_tiers:
    - "LIMITED"
    - "HIGH"
  triggered_by_code_categories:
    - "gpai" # General AI that might interact
    - "emotion_recognition" # If used in interactive systems
    - "generative_ai_media_manipulation" # For generated content
  file_types_to_search:
    - "*.md"
    - "*.txt"
    - "*.html"
    - "*.js"

- id: technical_documentation_robustness
  criterion: "Technical Documentation and Robustness"
  description: "High-risk AI systems must be accompanied by technical documentation detailing their purpose, capabilities, limitations, and how they meet requirements for accuracy, robustness, and cybersecurity."
  keywords:
    - "technical documentation"
    - "system architecture"
    - "accuracy assessment"
    - "robustness testing"
    - "cybersecurity measures"
    - "model card"
    - "system limitations"
    - "conformity assessment"
  relevant_risk_tiers:
    - "HIGH"
  triggered_by_code_categories:
    - "system_development"
    - "system_testing"
    - "system_deployment"
  file_types_to_search:
    - "*.md"
    - "*.pdf"
    - "*.docx"
    - "*.txt"
    - "*.rst"

- id: record_keeping_high_risk
  criterion: "Record Keeping for High-Risk AI Systems"
  description: "High-risk AI systems must be designed to automatically record events ('logs') relevant for tracing the system's operational history and identifying potential risks or non-compliance. These logs should be secure, accessible for audit, and cover aspects like the period of use, reference database, input data, and system's operational conditions."
  keywords:
    - "audit log"
    - "event log"
    - "system log"
    - "traceability"
    - "record keeping"
    - "logging mechanism"
    - "data input log"
    - "operational history"
    - "secure log"
  relevant_risk_tiers:
    - "HIGH"
  triggered_by_code_categories:
    - "biometric_processing"
    - "safety_critical_control"
    - "predictive_analytics_law_enforcement"
    - "critical_decision_making_employment"
    - "critical_decision_making_essential_services"
  file_types_to_search:
    - "*.py"
    - "*.java"
    - "*.cs"
    - "*.go"
    - "*.rb"
    - "*.md"
    - "*.txt"
    - "*.yaml"
    - "*.json"

- id: prohibited_biometric_identification_public_spaces
  criterion: "Prohibition of Real-Time Remote Biometric Identification in Publicly Accessible Spaces for Law Enforcement"
  description: "The EU AI Act prohibits the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement, subject to narrow exceptions."
  keywords:
    - "real-time biometric"
    - "public space surveillance"
    - "facial recognition public"
    - "law enforcement biometrics"
  relevant_risk_tiers: # This is a prohibition, so it applies regardless of a calculated tier
    - "PROHIBITED" # Or could be all tiers to ensure it's always checked if signals appear
    - "HIGH"
    - "LIMITED"
    - "MINIMAL"
  triggered_by_code_categories:
    - "biometric_processing"
    - "surveillance_and_monitoring"
  file_types_to_search:
    - "*.md"
    - "*.txt"
    - "*.py"

- id: transparency_for_emotion_recognition_systems
  criterion: "Transparency Obligations for Emotion Recognition and Biometric Categorisation Systems"
  description: "Providers of emotion recognition systems or biometric categorisation systems must ensure transparency. Individuals exposed to such systems must be informed of their operation."
  keywords:
    - "emotion detection disclosure"
    - "biometric categorization notice"
    - "informing users emotion AI"
  relevant_risk_tiers:
    - "LIMITED" # Typically a Limited Risk transparency obligation
    - "HIGH" # Could also be part of a High-Risk system
  triggered_by_code_categories:
    - "emotion_recognition"
    - "biometric_processing" # If used for categorization beyond simple ID
  file_types_to_search:
    - "*.md"
    - "*.txt"
    - "*.html"
    - "*.js" # For web interfaces

- id: deep_fake_transparency
  criterion: "Transparency of AI systems that generate or manipulate image, audio or video content (Deep Fakes)"
  description: "Users interacting with AI-generated or manipulated content (deep fakes) that appears authentic must be informed that the content is artificially generated or manipulated, with some exceptions for legitimate purposes (e.g., parody, art)."
  keywords:
    - "deep fake disclosure"
    - "AI generated content notice"
    - "synthetic media label"
    - "manipulated content warning"
  relevant_risk_tiers:
    - "LIMITED"
    - "HIGH"
  triggered_by_code_categories:
    - "generative_ai_media_manipulation"
  file_types_to_search:
    - "*.md"
    - "*.txt"
    - "*.html"
    - "*.js" # For web interfaces
